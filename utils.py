# ðŸ“¦ Proje yapÄ±sÄ±
#
# Streamlit Ã§ok sayfalÄ± uygulama (pages klasÃ¶rÃ¼ ile)
#
# â”œâ”€â”€ requirements.txt
# â”œâ”€â”€ utils.py
# â”œâ”€â”€ Home.py
# â””â”€â”€ pages/
#     â”œâ”€â”€ 1_Ã‡ok_ÃœrÃ¼nlÃ¼_SipariÅŸler.py
#     â”œâ”€â”€ 2_Ã‡ok_SipariÅŸ_Verenler.py
#     â”œâ”€â”€ 3_Toplam_Miktar_EÅŸiÄŸi.py
#     â”œâ”€â”€ 4_AynÄ±_ÃœrÃ¼nÃ¼_FarklÄ±_SipariÅŸlerde_Alanlar.py
#     â”œâ”€â”€ 5_Harita_ÃœrÃ¼n_BazlÄ±_GÃ¶rselleÅŸtirme.py
#     â””â”€â”€ 6_Raporlar_Excel_Ä°ndir.py
#
# Ã‡alÄ±ÅŸtÄ±rma:
#   pip install -r requirements.txt
#   streamlit run Home.py

# ========================= requirements.txt =========================
# Ä°Ã§erik:
# streamlit>=1.36
# pandas>=2.2
# openpyxl>=3.1
# geopy>=2.4
# pydeck>=0.9
# altair>=5.3
# numpy>=1.26

# ============================== utils.py ==============================
import io
import re
from typing import Dict, List, Optional

import pandas as pd
import streamlit as st
import sqlite3
import time
from pathlib import Path

# ---- Sabit kolonlar ----
ORDER_COL = "SipariÅŸ NumarasÄ±"
BUYER_COL = "AlÄ±cÄ±"
ADDR_COLS = ["Teslimat Adresi", "Ä°l", "Ä°lÃ§e"]
PRODUCT_COL = "ÃœrÃ¼n AdÄ±"
QTY_COL = "Adet"
AMOUNT_COL = "Faturalanacak Tutar"
IGNORED_COL = "MÃ¼ÅŸteri SipariÅŸ Adedi"  # asla kullanÄ±lmaz

ALL_COLS = [ORDER_COL, BUYER_COL, *ADDR_COLS, PRODUCT_COL, QTY_COL, AMOUNT_COL, IGNORED_COL]

# Termin SÃ¼resi Bitenler sayfasÄ± iÃ§in gerekli kolonlar
TERMIN_COLS = [
    'Barkod', 'Paket No', 'Kargo FirmasÄ±', 'SipariÅŸ Tarihi',
    'Termin SÃ¼resinin BittiÄŸi Tarih', 'Kargoya Teslim Tarihi', 'Kargo Kodu',
    'SipariÅŸ NumarasÄ±', 'AlÄ±cÄ±', 'Teslimat Adresi', 'Ä°l', 'Ä°lÃ§e',
    'ÃœrÃ¼n AdÄ±', 'Fatura Adresi', 'AlÄ±cÄ± - Fatura Adresi', 'SipariÅŸ StatÃ¼sÃ¼',
    'E-Posta', 'Komisyon OranÄ±', 'Marka', 'Stok Kodu', 'Adet',
    'Birim FiyatÄ±', 'SatÄ±ÅŸ TutarÄ±', 'Ä°ndirim TutarÄ±',
    'Trendyol Ä°ndirim TutarÄ±', 'Faturalanacak Tutar', 'Butik NumarasÄ±',
    'Teslim Tarihi', 'Kargodan alÄ±nan desi', 'HesapladÄ±ÄŸÄ±m desi',
    'Faturalanan Kargo TutarÄ±', 'Alternatif Teslimat StatÃ¼sÃ¼',
    'Kurumsal FaturalÄ± SipariÅŸ', 'Vergi Kimlik NumarasÄ±', 'Vergi Dairesi',
    'Åžirket Ä°smi', 'Fatura', 'MÃ¼ÅŸteri SipariÅŸ Adedi', 'Mikro Ä°hracat',
    'ETGB No', 'ETGB Tarihi', 'YaÅŸ', 'Cinsiyet', 'Kargo Partner Ä°smi',
    '2.Teslimat Paketi StatÃ¼sÃ¼', '2.Teslimat Takip NumarasÄ±',
    'Teslimat NumarasÄ±', 'Fatura No', 'Fatura Tarihi', 'Ãœlke',
    'MÃ¼ÅŸteri Telefon No', 'ETGB StatÃ¼sÃ¼'
]

def is_termin_excel(df: pd.DataFrame) -> bool:
    """Excel dosyasÄ± Termin SÃ¼resi Bitenler formatÄ±nda mÄ±?"""
    return all(col in df.columns for col in TERMIN_COLS)

# ---- YardÄ±mcÄ±lar ----
def norm_text(x: str) -> str:
    if pd.isna(x):
        return x
    x = re.sub(r"\s+", " ", str(x)).strip()
    return x


def to_number(x):
    """
    Para/metin -> float
    Desteklenen Ã¶rnekler:
      - "1.234,56"  (TR) -> 1234.56
      - "1,234.56"  (EN) -> 1234.56
      - "1234,56"   (virgÃ¼l ondalÄ±k) -> 1234.56
      - "1234.56"   (nokta ondalÄ±k)  -> 1234.56
      - "2.000"     (binlik nokta, ondalÄ±ksÄ±z) -> 2000.0
      - "2,000"     (binlik virgÃ¼l, ondalÄ±ksÄ±z) -> 2000.0
      - "â‚º1.234,56", "1.234,56 TL" vs.
    """
    import re
    if pd.isna(x):
        return None

    s = str(x).strip()
    if not s:
        return None

    # Para birimi ve boÅŸluk temizliÄŸi
    s = s.replace("â‚º", "").replace("TL", "").replace("TRY", "").strip()

    # Sadece rakam, nokta, virgÃ¼l, eksi, artÄ± tut
    s = re.sub(r"[^0-9,.\-+]", "", s)

    if not s:
        return None

    # 1) Hem nokta hem virgÃ¼l varsa: TR mi EN mi ayÄ±rt et
    if "," in s and "." in s:
        # TR kalÄ±bÄ±: 1.234,56  (binlik=., ondalÄ±k=,)
        if re.fullmatch(r"\d{1,3}(\.\d{3})+,\d{2}", s) or re.fullmatch(r"\d+,\d{2}", s):
            s = s.replace(".", "").replace(",", ".")
            try:
                return float(s)
            except Exception:
                return None
        # EN kalÄ±bÄ±: 1,234.56  (binlik=,, ondalÄ±k=.)
        if re.fullmatch(r"\d{1,3}(,\d{3})+\.\d{2}", s) or re.fullmatch(r"\d+\.\d{2}", s):
            s = s.replace(",", "")
            try:
                return float(s)
            except Exception:
                return None
        # Belirsiz: son ayÄ±racÄ± ondalÄ±k varsay
        last_comma = s.rfind(",")
        last_dot = s.rfind(".")
        if last_comma > last_dot:
            # , ondalÄ±k; . binlik
            s = s.replace(".", "").replace(",", ".")
        else:
            # . ondalÄ±k; , binlik
            s = s.replace(",", "")
        try:
            return float(s)
        except Exception:
            return None

    # 2) Sadece virgÃ¼l varsa (Ã§oÄŸunlukla ondalÄ±k virgÃ¼l)
    if "," in s:
        # EÄŸer son 3 karakter iÃ§inde virgÃ¼l ve ardÄ±ndan 1-2 rakam varsa ondalÄ±k kabul et
        if re.fullmatch(r"\d+,\d{1,2}", s):
            s = s.replace(",", ".")
            try:
                return float(s)
            except Exception:
                return None
        # Yoksa muhtemelen binlik virgÃ¼l: tamamen virgÃ¼lleri kaldÄ±r
        try:
            return float(s.replace(",", ""))
        except Exception:
            return None

    # 3) Sadece nokta varsa
    if "." in s:
        # EÄŸer son 3 karakter iÃ§inde nokta ve ardÄ±ndan 1-2 rakam varsa ondalÄ±k kabul et
        if re.fullmatch(r"\d+\.\d{1,2}", s):
            try:
                return float(s)
            except Exception:
                return None
        # Yoksa binlik noktalarÄ± kaldÄ±r
        try:
            return float(s.replace(".", ""))
        except Exception:
            return None

    # 4) Sade rakam
    try:
        return float(s)
    except Exception:
        return None


@st.cache_data(show_spinner=False)
def load_and_clean_excel(file_bytes: bytes) -> pd.DataFrame:
    """TÃ¼m sheet'leri okur, birleÅŸtirir, normalize eder."""
    all_sheets = pd.read_excel(io.BytesIO(file_bytes), sheet_name=None)
    dfs = []
    for _, df in all_sheets.items():
        if not isinstance(df, pd.DataFrame):
            continue
        df = df.dropna(how="all")
        keep = [c for c in ALL_COLS if c in df.columns]
        if not keep:
            continue
        df = df[keep].copy()

        # Normalizasyon
        if BUYER_COL in df.columns:
            df[BUYER_COL] = df[BUYER_COL].map(norm_text).astype(str).str.title()
        if ORDER_COL in df.columns:
            df[ORDER_COL] = df[ORDER_COL].map(norm_text).astype(str)
        if PRODUCT_COL in df.columns:
            df[PRODUCT_COL] = df[PRODUCT_COL].map(norm_text).astype(str)
        if QTY_COL in df.columns:
            df[QTY_COL] = pd.to_numeric(df[QTY_COL], errors="coerce").fillna(0).astype(int)
        if AMOUNT_COL in df.columns:
            df[AMOUNT_COL] = df[AMOUNT_COL].apply(to_number)

        dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    final_df = pd.concat(dfs, ignore_index=True)
    final_df = final_df.dropna(how="all")
    return final_df


def to_excel_bytes(dfs: Dict[str, pd.DataFrame] | pd.DataFrame, filename: Optional[str] = None) -> bytes:
    """Tek DF veya {sheet_name: DF} sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ xlsx byte'Ä±na Ã§evirir."""
    buf = io.BytesIO()
    if isinstance(dfs, pd.DataFrame):
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            dfs.to_excel(writer, index=False, sheet_name="Sheet1")
    else:
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            for sheet, df in dfs.items():
                # Excel sheet adÄ± 31 karakteri aÅŸmamalÄ±
                sheet_name = str(sheet)[:31] if sheet else "Sheet"
                df.to_excel(writer, index=False, sheet_name=sheet_name)
    buf.seek(0)
    return buf.read()


# ---- Oturum veri paylaÅŸÄ±mÄ± ----
SESSION_DF_KEY = "__MAIN_DF__"
SESSION_FILE_NAME = "__FILE_NAME__"
SESSION_RAW_DF_KEY = "__RAW_DF__"
SESSION_RAW_SHEETS_KEY = "__RAW_SHEETS__"


def set_df(df: pd.DataFrame, file_name: str | None = None):
    st.session_state[SESSION_DF_KEY] = df
    if file_name:
        st.session_state[SESSION_FILE_NAME] = file_name


def set_raw_df(raw_df: pd.DataFrame, sheets: dict | None = None, file_name: str | None = None):
    """Store raw/unmodified dataframe (or combined raw) and optionally raw sheets dict in session."""
    st.session_state[SESSION_RAW_DF_KEY] = raw_df
    if sheets is not None:
        st.session_state[SESSION_RAW_SHEETS_KEY] = sheets
    if file_name:
        st.session_state[SESSION_FILE_NAME] = file_name


def get_df() -> Optional[pd.DataFrame]:
    return st.session_state.get(SESSION_DF_KEY)


def get_raw_df() -> Optional[pd.DataFrame]:
    return st.session_state.get(SESSION_RAW_DF_KEY)


def get_raw_sheets() -> Optional[dict]:
    return st.session_state.get(SESSION_RAW_SHEETS_KEY)


def get_file_name(default: str = "veri.xlsx") -> str:
    return st.session_state.get(SESSION_FILE_NAME, default)


# ---- HazÄ±r Ã¶zetler/hesaplar ----
@st.cache_data(show_spinner=False)
def buyer_summary(df: pd.DataFrame) -> pd.DataFrame:
    base = df[[BUYER_COL, ORDER_COL]].drop_duplicates()
    order_counts = base.groupby(BUYER_COL)[ORDER_COL].nunique().rename("FarklÄ± SipariÅŸ SayÄ±sÄ±")
    qty_sum = df.groupby(BUYER_COL)[QTY_COL].sum().rename("Toplam Adet")
    if AMOUNT_COL in df.columns:
        amount_sum = df.groupby(BUYER_COL)[AMOUNT_COL].sum().rename("Toplam Tutar")
        out = pd.concat([order_counts, qty_sum, amount_sum], axis=1).reset_index()
    else:
        out = pd.concat([order_counts, qty_sum], axis=1).reset_index()
    return out.fillna(0)


@st.cache_data(show_spinner=False)
def orders_with_many_products(df: pd.DataFrame) -> pd.DataFrame:
    grp = df.groupby(ORDER_COL)[PRODUCT_COL].nunique().reset_index(name="FarklÄ± ÃœrÃ¼n SayÄ±sÄ±")
    return grp


@st.cache_data(show_spinner=False)
def buyers_over_total_qty(df: pd.DataFrame) -> pd.DataFrame:
    return df.groupby(BUYER_COL)[QTY_COL].sum().reset_index(name="Toplam Adet")


@st.cache_data(show_spinner=False)
def same_product_across_distinct_orders(df: pd.DataFrame, products: List[str]) -> pd.DataFrame:
    sub = df[df[PRODUCT_COL].isin(products)][[BUYER_COL, PRODUCT_COL, ORDER_COL]].drop_duplicates()
    out = (
        sub.groupby([BUYER_COL, PRODUCT_COL])[ORDER_COL]
        .nunique()
        .reset_index(name="FarklÄ± SipariÅŸ SayÄ±sÄ±")
    )
    return out


# ---- Geocoding ----
@st.cache_data(show_spinner=True)
def geocode_unique_addresses(addresses: List[str], provider: str = "ArcGIS") -> pd.DataFrame:
    """Adres listesi â†’ lat/lon. provider: 'ArcGIS' (varsayÄ±lan) veya 'Nominatim'."""
    from geopy.extra.rate_limiter import RateLimiter
    if provider == "Nominatim":
        from geopy.geocoders import Nominatim
        geocoder = Nominatim(user_agent="streamlit-addr-geocoder")
        rate = RateLimiter(geocoder.geocode, min_delay_seconds=1.0)
    else:
        from geopy.geocoders import ArcGIS
        geocoder = ArcGIS(timeout=10)
        rate = RateLimiter(geocoder.geocode, min_delay_seconds=0.2)

    rows = []
    for a in addresses:
        if not a or not str(a).strip():
            rows.append({"address": a, "lat": None, "lon": None})
            continue
        try:
            loc = rate(a)
            if loc:
                rows.append({"address": a, "lat": loc.latitude, "lon": loc.longitude})
            else:
                rows.append({"address": a, "lat": None, "lon": None})
        except Exception:
            rows.append({"address": a, "lat": None, "lon": None})
    return pd.DataFrame(rows)


# ----------------- Geocode cache (SQLite) -----------------
DB_PATH = Path(__file__).parent / "geocode_cache.sqlite"

def init_geo_db():
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS geo_cache (
            id INTEGER PRIMARY KEY,
            il TEXT,
            ilce TEXT,
            address TEXT,
            lat REAL,
            lon REAL,
            provider TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(il, ilce, provider)
        )
        """
    )
    con.commit()
    con.close()


def get_cached_coords(il: str, ilce: str, provider: str = "ArcGIS") -> tuple | None:
    init_geo_db()
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute("SELECT lat, lon, address FROM geo_cache WHERE il=? AND ilce=? AND provider=?", (il, ilce, provider))
    row = cur.fetchone()
    con.close()
    if row:
        return (row[0], row[1], row[2])
    return None


def set_cached_coords(il: str, ilce: str, address: str, lat: float, lon: float, provider: str = "ArcGIS"):
    init_geo_db()
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    try:
        cur.execute(
            "INSERT OR REPLACE INTO geo_cache (il, ilce, address, lat, lon, provider) VALUES (?, ?, ?, ?, ?, ?)",
            (il, ilce, address, lat, lon, provider),
        )
        con.commit()
    finally:
        con.close()


def geocode_il_ilce(pairs: List[tuple], provider: str = "ArcGIS", sleep: float = 0.2) -> pd.DataFrame:
    """pairs: list of (il, ilce). Returns DataFrame with il, ilce, address, lat, lon.
    Uses SQLite cache to avoid re-geocoding existing rows."""
    results = []
    # prepare geocoder
    if provider == "Nominatim":
        from geopy.geocoders import Nominatim
        geocoder = Nominatim(user_agent="streamlit-addr-geocoder")
        rate_sleep = 1.0
    else:
        from geopy.geocoders import ArcGIS
        geocoder = ArcGIS(timeout=10)
        rate_sleep = sleep

    for il, ilce in pairs:
        il_s = str(il).strip() if pd.notna(il) else ""
        ilce_s = str(ilce).strip() if pd.notna(ilce) else ""
        if not il_s and not ilce_s:
            continue
        cache = get_cached_coords(il_s, ilce_s, provider=provider)
        if cache:
            lat, lon, address = cache[0], cache[1], cache[2]
            results.append({"il": il_s, "ilce": ilce_s, "address": address, "lat": lat, "lon": lon})
            continue

        # build simple query: "Ä°lÃ§e, Ä°l, TÃ¼rkiye"
        query = f"{ilce_s}, {il_s}, TÃ¼rkiye" if ilce_s else f"{il_s}, TÃ¼rkiye"
        try:
            loc = geocoder.geocode(query)
            if loc:
                lat, lon = float(loc.latitude), float(loc.longitude)
                address = loc.address if hasattr(loc, "address") else query
                set_cached_coords(il_s, ilce_s, address, lat, lon, provider=provider)
                results.append({"il": il_s, "ilce": ilce_s, "address": address, "lat": lat, "lon": lon})
            else:
                results.append({"il": il_s, "ilce": ilce_s, "address": None, "lat": None, "lon": None})
        except Exception:
            results.append({"il": il_s, "ilce": ilce_s, "address": None, "lat": None, "lon": None})
        time.sleep(rate_sleep)

    return pd.DataFrame(results)


def build_full_address(df: pd.DataFrame, use_fields: List[str]) -> pd.Series:
    parts = [df[c].fillna("") if c in df.columns else "" for c in use_fields]
    # "Adres, Ä°lÃ§e, Ä°l" ÅŸeklinde birleÅŸtir
    ser = (
        pd.DataFrame({i: p for i, p in enumerate(parts)})
        .astype(str)
        .apply(lambda r: ", ".join([x for x in r.tolist() if x and str(x).strip()]), axis=1)
        .map(norm_text)
    )
    return ser


def prepare_page_df(required_cols: List[str], page_key: str = "page") -> tuple:
    """Return (raw_df, view_df, mapping) for a page.

    - raw_df: the complete original dataframe from session (get_raw_df)
    - view_df: a DataFrame view that contains all raw columns plus aliases for required_cols
    - mapping: dict(required_col -> chosen existing column or None)

    If raw_df is missing, raises ValueError.
    If some required cols are missing, shows UI to let user map existing columns to required names.
    """
    raw = get_raw_df()
    if raw is None or raw.empty:
        raise ValueError("Ham veri bulunamadÄ±. LÃ¼tfen Ana Sayfa'dan dosya yÃ¼kleyin.")

    # Normalize raw column names
    raw_cols = [str(c).strip() for c in raw.columns]
    mapping = {}
    view = raw.copy()

    for rc in required_cols:
        if rc in view.columns:
            mapping[rc] = rc
            continue
        # Offer mapping UI: allow user to pick an existing column to serve as rc
        opts = ["<none>"] + raw_cols
        sel = st.selectbox(f"{page_key}: '{rc}' bulunamadÄ± â€” eÅŸleÅŸtirmek iÃ§in bir sÃ¼tun seÃ§in (veya <none>)", opts, key=f"map_{page_key}_{rc}")
        if sel and sel != "<none>":
            mapping[rc] = sel
            # create alias column name if different
            if sel in view.columns:
                view[rc] = view[sel]
        else:
            mapping[rc] = None

    return raw, view, mapping

